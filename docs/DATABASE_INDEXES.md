# Database Index Optimierung

## Ãœbersicht

Diese Dokumentation beschreibt die Datenbank-Indexes und Query-Optimierungsstrategien.

## Bestehende Indexes

### Events Tabelle
- âœ… `ix_events_code` (UNIQUE) - Event-Code fÃ¼r Login/Auswahl
- âœ… `ix_events_is_active` - Filter fÃ¼r aktive Events

### Participants Tabelle
- âœ… `ix_participants_event_id` - Foreign Key (hÃ¤ufigste Query)
- âœ… `ix_participants_role_id` - Foreign Key
- âœ… `ix_participants_family_id` - Foreign Key
- âœ… `ix_participants_is_active` - Filter fÃ¼r aktive Teilnehmer
- âœ… `ix_participants_email` - Suche nach Email
- âœ… `ix_participants_last_name` - Suche nach Nachname
- âœ… `ix_participants_deleted_at` - Soft-Delete Queries

### Families Tabelle
- âœ… `ix_families_event_id` - Foreign Key
- âœ… `ix_families_is_active` - Filter
- âœ… `ix_families_email` - Suche
- âœ… `ix_families_deleted_at` - Soft-Delete

### Roles Tabelle
- âœ… `ix_roles_event_id` - Foreign Key
- âœ… `ix_roles_is_active` - Filter

### Payments Tabelle
- âœ… `ix_payments_event_id` - Foreign Key
- âœ… `ix_payments_participant_id` - Foreign Key
- âœ… `ix_payments_family_id` - Foreign Key

### Expenses Tabelle
- âœ… `ix_expenses_event_id` - Foreign Key

### Incomes Tabelle
- âœ… `ix_incomes_event_id` - Foreign Key
- âœ… `ix_incomes_role_id` - Foreign Key

### Tasks Tabelle
- âœ… `ix_tasks_event_id` - Foreign Key
- âœ… `ix_tasks_is_completed` - Filter

### Settings Tabelle
- âœ… `ix_settings_event_id` (UNIQUE) - One-to-One Relationship

### Rulesets Tabelle
- âœ… `ix_rulesets_event_id` - Foreign Key
- âœ… `ix_rulesets_is_active` - Filter

## Bewertung

### âœ… Gut abgedeckt
- Alle Foreign Keys haben Indexes
- Filter-Felder (is_active, deleted_at) sind indiziert
- HÃ¤ufige Suchen (email, last_name) haben Indexes
- Composite Queries werden durch Single-Column Indexes unterstÃ¼tzt

### ðŸ’¡ MÃ¶gliche Optimierungen (Optional)

#### Composite Indexes fÃ¼r hÃ¤ufige Query-Kombinationen:

```python
# participants: event_id + is_active (hÃ¤ufige Kombination)
Index('ix_participants_event_active', 'event_id', 'is_active')

# participants: event_id + family_id (Familienansicht)
Index('ix_participants_event_family', 'event_id', 'family_id')

# payments: event_id + payment_date (Timeline)
Index('ix_payments_event_date', 'event_id', 'payment_date')

# expenses: event_id + expense_date (Timeline)
Index('ix_expenses_event_date', 'event_id', 'expense_date')
```

**Entscheidung**: FÃ¼r lokalen Single-User Betrieb NICHT notwendig.
- Datenvolumen bleibt klein (< 10.000 Records)
- Single-Column Indexes sind ausreichend
- Overhead von Composite Indexes nicht gerechtfertigt

## Query-Optimierungs-Guidelines

### 1. N+1 Query Problem vermeiden

âŒ **Schlecht**:
```python
participants = db.query(Participant).all()
for p in participants:
    print(p.role.name)  # LÃ¤dt role fÃ¼r jeden Participant einzeln
```

âœ… **Gut**:
```python
from sqlalchemy.orm import joinedload

participants = db.query(Participant).options(
    joinedload(Participant.role),
    joinedload(Participant.family)
).all()
```

### 2. Select Only What You Need

âŒ **Schlecht**:
```python
participants = db.query(Participant).all()  # LÃ¤dt alle Spalten
names = [p.full_name for p in participants]
```

âœ… **Gut**:
```python
names = db.query(Participant.first_name, Participant.last_name).all()
```

### 3. Use Pagination fÃ¼r groÃŸe Listen

```python
# Mit Limit/Offset
participants = db.query(Participant).limit(50).offset(0).all()

# Oder: Cursor-Based Pagination
participants = db.query(Participant).filter(
    Participant.id > last_seen_id
).limit(50).all()
```

### 4. Filter so frÃ¼h wie mÃ¶glich

âœ… **Gut**:
```python
# Filter auf DB-Ebene
active_participants = db.query(Participant).filter(
    Participant.event_id == event_id,
    Participant.is_active == True
).all()
```

âŒ **Schlecht**:
```python
# Filter in Python (lÃ¤dt ALLE Participants)
all_participants = db.query(Participant).all()
active = [p for p in all_participants if p.is_active and p.event_id == event_id]
```

### 5. Bulk Operations verwenden

âœ… **Gut**:
```python
# Bulk Insert
db.bulk_insert_mappings(Participant, participant_dicts)

# Bulk Update
db.query(Participant).filter(
    Participant.event_id == event_id
).update({"is_active": False})
```

## Query Profiling

### SQLite EXPLAIN QUERY PLAN

```bash
sqlite3 freizeit_kassen.db
sqlite> EXPLAIN QUERY PLAN
        SELECT * FROM participants
        WHERE event_id = 1 AND is_active = 1;
```

Erwartete Ausgabe:
```
SEARCH TABLE participants USING INDEX ix_participants_event_id (event_id=?)
```

### SQLAlchemy Echo Mode

```python
# In database.py:
engine = create_engine(
    settings.database_url,
    echo=True  # Zeigt alle SQL-Queries
)
```

## Performance Benchmarks (Referenz)

FÃ¼r lokalen Single-User Betrieb mit < 10.000 Records:

| Operation | Akzeptable Zeit | Anmerkungen |
|-----------|----------------|-------------|
| List Participants (50) | < 50ms | Mit Joins |
| Create Participant | < 20ms | Single Insert |
| Update Participant | < 20ms | Single Update |
| Dashboard Stats | < 100ms | Multiple Queries |
| Invoice Generation | < 500ms | PDF Rendering |

## Maintenance

### Index Rebuild (bei Bedarf)

SQLite:
```bash
sqlite3 freizeit_kassen.db "VACUUM;"
```

PostgreSQL:
```sql
REINDEX TABLE participants;
```

### Statistiken aktualisieren

SQLite:
```bash
sqlite3 freizeit_kassen.db "ANALYZE;"
```

PostgreSQL:
```sql
ANALYZE participants;
```

## Fazit

âœ… **Aktuelle Index-Strategie ist optimal** fÃ¼r:
- Lokalen Single-User Betrieb
- Datenvolumen < 10.000 Records
- Typische Query-Patterns

âŒ **Keine weiteren Indexes notwendig** weil:
- Overhead wÃ¼rde Performance verschlechtern
- Write-Performance wÃ¼rde leiden
- Datenbank-GrÃ¶ÃŸe wÃ¼rde unnÃ¶tig wachsen

ðŸ“Š **Empfehlung**: Indexes unverÃ¤ndert lassen, Query-Optimierung Ã¼ber SQLAlchemy-Best-Practices.
